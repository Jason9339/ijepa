# I-JEPA 程式測試指南 (SLURM版本)

## 快速測試（推薦）

### 智能自動測試（最推薦）
執行智能測試腳本，自動檢查資源並提交最合適的作業：

```bash
./快速測試.sh
```

這個腳本會：
- 自動檢查所有可用的GPU和CPU資源
- 智能推薦最佳的測試選項
- 一鍵提交最合適的作業

### 手動選擇測試版本

根據您的SLURM環境，我們提供三種測試選項：

#### A100 GPU版本測試（最快）
如果您有A100 GPU存取權限：

```bash
sbatch slurm_test_ijepa_a100.sh
```

#### V100 GPU版本測試
如果有V100 GPU資源可用：

```bash
sbatch slurm_test_ijepa.sh
```

#### CPU版本測試
如果只有CPU資源：

```bash
sbatch slurm_test_ijepa_cpu.sh
```

## 檢查資源可用性

### 檢視可用GPU資源
```bash
# 檢視A100資源
sinfo -p a100_short-al9

# 檢視V100資源  
sinfo -p v100-al9_short

# 檢視L40S資源
sinfo -p l40s-al9_short

# 檢視CPU資源
sinfo -p edr1-al9_short
```

### 檢查作業佇列
```bash
# 檢視您的所有作業
squeue -u $USER

# 檢視特定分區的作業
squeue -p a100_short-al9
squeue -p v100-al9_short
squeue -p edr1-al9_short
```

### 檢視作業詳情
```bash
scontrol show job <jobid>
```

### 取消作業
```bash
scancel <jobid>
```

## 手動測試步驟

### 1. 建立互動式會話測試

#### A100 GPU互動式會話
```bash
salloc --partition=a100_short-al9 --gres=gpu:1 --time=1:00:00 --mem=32G
```

#### V100 GPU互動式會話
```bash
salloc --partition=v100-al9_short --gres=gpu:1 --time=1:00:00 --mem=32G
```

#### CPU互動式會話  
```bash
salloc --partition=edr1-al9_short --cpus-per-task=8 --time=1:00:00 --mem=16G
```

### 2. 在互動式會話中執行
```bash
# 載入模組
module load anaconda3/2024.10-1
module load cuda/12.6.0  # 僅GPU版本需要
module load gcc/13.1.0

# 創建測試資料
python3 create_test_data.py

# 運行測試 (GPU)
python3 main.py --fname configs/test_config.yaml --devices cuda:0

# 運行測試 (CPU)
python3 main.py --fname configs/test_config.yaml --devices cpu
```

## 檔案系統配置

### 資料位置
- **測試資料**: `/ceph/sharedfs/$USER/test_data/`
- **日誌檔案**: `$SLURM_SUBMIT_DIR/test_logs/`
- **SLURM輸出**: 
  - A100: `ijepa_test_a100.<jobid>.out`
  - V100: `ijepa_test.<jobid>.out` 
  - CPU: `ijepa_test_cpu.<jobid>.out`

### 路徑設定
配置檔案 `configs/test_config.yaml` 已設定為使用並行檔案系統：
- `root_path: /ceph/sharedfs/$USER/test_data`
- `folder: $SLURM_SUBMIT_DIR/test_logs/`

## 測試配置說明

- **epochs: 1** - 只運行1個訓練輪次
- **batch_size: 4** - 小批次大小，減少記憶體使用
- **model_name: vit_tiny** - 使用最小的模型
- **num_workers: 4** - 適應cluster環境的資料載入程序數
- **use_bfloat16: false** - 關閉混合精度，提高相容性

## 系統環境

### 載入的模組
- `anaconda3/2024.10-1` - Python環境
- `cuda/12.6.0` - CUDA支援（GPU版本）
- `gcc/13.1.0` - 編譯器

### 可用分區
- **A100 GPU**: `a100_short-al9` (6小時限制)
- **V100 GPU**: `v100-al9_short` (6小時限制)  
- **CPU**: `edr1-al9_short` (3小時限制)

## 預期執行時間

- **A100版本**: 3-8分鐘
- **V100版本**: 5-15分鐘
- **CPU版本**: 30-90分鐘

## 檢視結果

### 即時監控
```bash
# 查看A100輸出檔案
tail -f ijepa_test_a100.<jobid>.out

# 查看V100輸出檔案
tail -f ijepa_test.<jobid>.out

# 查看CPU輸出檔案
tail -f ijepa_test_cpu.<jobid>.out

# 查看錯誤檔案
tail -f ijepa_test*.<jobid>.err
```

### 成功輸出範例
```
================================================================
I-JEPA 測試作業開始
作業ID: 12345
節點: hp-teslav02
================================================================
檢查Python環境和依賴...
Python 3.9.23
PyTorch版本: 2.x.x
CUDA可用: True
GPU數量: 1
================================================================
創建測試資料...
為類別 n00000000 創建了 10 張圖像
...
測試資料創建完成！
================================================================
開始I-JEPA訓練測試...
Initialized (rank/world-size) 0/1
ImageNet dataset created
ImageNet unsupervised data loader created
Epoch 1
[1,     0] loss: X.XXX masks: XX.X XX.X [wd: X.XXe-XX] [lr: X.XXe-XX] [mem: X.XXe+XX] (XXX.X ms)
avg. loss X.XXX
✓ I-JEPA測試成功完成！
```

## 常見問題

### 作業佇列中等待
如果作業在佇列中等待，檢查：
```bash
squeue -u $USER
sinfo -p a100_short-al9  # 或其他分區
```

### GPU不可用或被預約
如果看到`resv`狀態，表示GPU被預約，可以：
1. 等待或選擇其他分區
2. 使用V100替代A100
3. 使用CPU版本

### 記憶體不足
如果遇到記憶體不足：
1. 減少 `batch_size` 到 2 或 1
2. 在SLURM腳本中減少 `--mem` 參數

### 模組載入失敗
確保模組可用：
```bash
module avail anaconda3
module avail cuda
module avail gcc
```

### 檔案權限問題
確保對並行檔案系統有寫入權限：
```bash
ls -la /ceph/sharedfs/$USER/
mkdir -p /ceph/sharedfs/$USER/test_data
```

## 清理資源

### 清理測試資料
```bash
rm -rf /ceph/sharedfs/$USER/test_data
rm -rf ./test_logs
```

### 清理SLURM檔案
```bash
rm ijepa_test*.out ijepa_test*.err
```

## 選擇合適的版本

### 建議選擇順序
1. **A100版本** - 如果可用且無佇列，速度最快
2. **V100版本** - 穩定的GPU選擇，通常可用性較好
3. **CPU版本** - 保證可用，但較慢

### 查看即時資源狀況
```bash
# 一鍵查看所有GPU分區狀況
sinfo -p a100_short-al9,v100-al9_short,l40s-al9_short
```

## 完整訓練準備

測試成功後，準備完整訓練：

1. **準備真實資料集**: 將ImageNet資料放到並行檔案系統
2. **修改配置檔案**: 更新路徑和訓練參數
3. **建立完整訓練腳本**: 
```bash
#!/bin/bash
#SBATCH --job-name=ijepa_full_train
#SBATCH --partition=v100-al9_long
#SBATCH --gres=gpu:4
#SBATCH --time=7-00:00:00
#SBATCH --mem=200G

module load anaconda3/2024.10-1
module load cuda/12.6.0
module load gcc/13.1.0

srun python3 main.py --fname configs/in1k_vith14_ep300.yaml --devices cuda:0 cuda:1 cuda:2 cuda:3
```

## 支援

如遇問題，請檢查：
1. SLURM輸出檔案: `ijepa_test*.<jobid>.out`
2. SLURM錯誤檔案: `ijepa_test*.<jobid>.err`
3. 程式日誌: `./test_logs/test_jepa_r0.csv`
4. 系統資源: `sinfo`, `squeue -u $USER`